---
title: "ML_Project_Intro"
author: "Sarah Deussing & Imogen Meers"
date: "2024-09-20"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Motivation
#### What is the problem you are considering and why is this an interesting problem? Has this problem been attempted before?

Our group is working with Los Angeles crime data from 2021-2024. The dataset is divided into region and lists the date, time, and type of crime. This is an interesting problem because of its practical implications - after identification of areas with high crime, the Los Angeles police department can place more officers at such locations (and at certain identified times).

This problem has been attempted by other people on Kaggle. One such analysis looked at the crime rate per year and the time of day where the most crime occurs. This analysis also found the most likely victim of crime. Another analysis on Kaggle visualized the amount of crime by victim, area, and time of day. There were several other analyses on Kaggle performing the same operations as these two.

Our analysis will be unique in that we are going to introduce several derived variables (explained in the Data Overview section below). We will also be using machine learning models to predict the type and time of crime, rather than producing mostly descriptive outputs.

## Problem Framing
#### What is the proposed solution to the problem?

Our proposed solution can be divided into 2 parts.

Part 1:
Our plan is to identify districts of Los Angeles and times of the day that are "high crime." We will do so via clustering methods, and we will account for the severity of the crime and vulnerability of victim in our analysis.

Part 2:
Of the areas identified as "high-crime" in Part 1, we will then predict the next time and type of crime to occur.

## Data overview
#### What is the dataset you are going to use to solve this problem? Describe the dataset and its characteristics.

The dataset contains columns that give the date, time, and location (area code, area name, and exact location) of the reported crime. There are also columns for the use of weapons (yes/no), the crime code, and the longitude/latitude coordinates. 




We will create the following __row-wise derived variables__:

1. __Severity__ index that evaluates crime codes and assigns each crime a ranking of how severe the offense was

  - This information will be useful in deciding if an area is "high-crime." For example, if two areas have similar crime rates/totals, the crime severity will differentiate these two areas. 
  
  - By having a final, combined severity it also allows us to evaluate whether two minor crimes are worse than one major crime.
  
  - Upon research, we found the Uniform Crime Reporting User Manual, which gave a break down of how offenses should be classified. It described that a lower crime code indicated a more violent crime and that each crime is either part 1, a crime against person or property, or a less severe part 2 crime, which is any other crime. Using this information, we ordered each crime firstly by part, then by crime code and gave a severity index from 140 (most severe) to 1 to (least severe).
  
  a. Severity for Crime Code 1
  
  b. Severity for Crime Code 2
  
  c. Severity for Crime Code 3
  
  d. Final Severity, which is a weighted severity that takes into account each crime code. Crime code 1 is the primary offense so is 75% of final, crime code 2 is the secondary offesnse so is 25% of final and crime code 3 is the tertiary offense so is 10% of final
  
  
2. __Vulnerability__ index that evaluates age and gender of the victim and assigns a number to decide how vulnerable they would be
  - This is be calculated by 3 points for female and + 1 point for every year < 18 or > 60
  This eliminates some of our project's reproducability as it is subjective how much being female or "old" affects your vulnerability.
  
   
3. An indicator variable to describe gun (1) or not (0)

4. An indicator variable to describe blade (1) or not (0)

5. An indicator variable to describe Adult Arrest (1) or not

6. An indicator variable to describe Juv Arrest (1) or not (0)






From our row-wise derived variables, we will create __district-wise derived variables__ for use in clustering:

1. Mean Severity

2. Mean Vulnerability

3. Number of Gun Crimes

4. Number of Blade Crimes

5. Number of Adult Arrests

6. Number of Juvenile Arrests

7. Most common weapon type

8. Most common premises at which the crime occured (e.g. does District X have lots of crimes in family homes?)

9. Mean latitude

10. Mean longitude


The dataset can be accessed at:
https://catalog.data.gov/dataset/crime-data-from-2020-to-present

## Contribution
#### Which team members contributed to each area of the project.

Imogen Meers & Sarah Deussing

Both have contributed to data cleaning, initial analyses, and project description.

## Bibliography
#### Citations for the references used.

“City of Los Angeles - Crime Data from 2020 to Present.” Data.Gov, data.lacity.org, 20 Sept. 2024, catalog.data.gov/dataset/crime-data-from-2020-to-present. 

California Department of Justice. (2024). Law Enforcement Code Tables. Retrieved from https://oag.ca.gov/law/code-tables

## R-Code
#### R-script with code used for initial data analysis.


- Data overview, summary statistics, appropriate data visualization.


```{r Read in Data}
library(readr)
crime <- read_csv("Crime_Data_from_2020_to_Present.csv")
head(crime)
summary(crime)
```


```{r Clean Column Names: Eliminate Spaces}
#colnames(crime)
new_colnames <- c("DR_NO", "Date_Rptd", "Date_Occurred", "Time_Occurred", "Area",
                  "Area_Name","District_Num", "Part_1_2", "Crime_Code", "Crime_Code_Desc",
                  "Mocode", "Vict_Age", "Vict_Sex", "Vict_Descent", "Premis_Code",
                  "Premis_Desc", "Weapon_Used_Code", "Weapon_Desc", "Status", "Status_Desc",
                  "Crm_Cd1", "Crm_Cd2", "Crm_Cd3", "Crm_Cd4", "Location", "Cross_Street",
                  "LAT", "LON")
colnames(crime) <- new_colnames

```


```{r Number of Crimes by Area Code}
library(ggplot2)
by_area <- ggplot(crime, aes(x=Area)) + geom_bar() +
  labs(title = "Number of Crimes by Area Code",
       x = "Area Code",
       y = "Number of Crimes") +
  theme_minimal()
by_area
```

The areas with the most crime in the dataset are: 1, 3, 12, and 14.

```{r Number of Crimes by Victim Age and Sex}
filtered <-  crime[crime$Vict_Age > 0 & ((crime$Vict_Sex == 'F' | crime$Vict_Sex == 'M') & !is.na(crime$Vict_Sex)),]

by_age <- ggplot(filtered, aes(x=Vict_Age)) + 
  geom_histogram(fill = "grey", color = "black") +
  geom_histogram(data = filtered[filtered$Vict_Age > 0 & filtered$Vict_Age < 18 | filtered$Vict_Age >= 60,], fill = "red", color = 'black', ) + 
  labs(title = "Vulnerability- Number of Crimes by Victim Age and Sex",
       x = "Victim Age",
       y = "Number of Crimes") +
  theme_minimal() +
  annotate("text", x = 80, y = 30000, label = "Vunerable Population\n Age < 18 or Age > 60", color = "red", size = 3) +
  facet_wrap(~Vict_Sex)
by_age
```

The distribution of victim ages is relatively normal and similar between male and female with the most crimes being committed against males and females aged 25 to 50. From the area of each histogram you can see there is a roughly equal number of crimes committed against males and females. 

```{r Severity of Crimes by Area}
library(dplyr)
library(ggmap)


#Dataset including indicator variables for armed and arrested
indicators <- crime
indicators$Arrest <- ifelse((indicators$Status == 'JA' | indicators$Status == 'AA') & !is.na(indicators$Status), 1, 0)
indicators$Armed <- ifelse(!is.na(indicators$Weapon_Used_Code), 1, 0)


#Summary Table by Area
summary_by_area <- indicators[indicators$LON != 0 & indicators$ LAT !=0,] %>%
  group_by(Area) %>%
  summarise(
    avg_lat = mean(LAT),
    avg_lon = mean(LON),
    Percent_Arrests = (sum(Arrest) / n()) * 100,
    Percent_Armed = (sum(Armed) / n()) * 100
  )

```

```{r}
#Plotting Crimes on LA MAP
register_stadiamaps("9e07144d-cdab-48f9-a35d-298e1bbece2e")

# Define the bounding box for Los Angeles
bbox <- c(left = -118.6682, bottom = 33.7037, right = -118, top = 34.3373)

# Get the map
la_map <- get_stadiamap(bbox = bbox, zoom = 12, maptype = "stamen_toner")


# Plot the map
armed_map <- ggmap(la_map) +
  geom_point(data = indicators, aes(x = LON, y = LAT, color = as.factor(Armed), alpha = 0.05)) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
  ) +
  scale_color_manual(
    values = c('1' = "red", '0' = "blue"),
    labels = c("Unarmed", "Armed")
  ) + 
  labs(
    title = "Map of LA showing all Crimes by Weapon Usage",
    color = "Weapon Usage"
  )+
  guides(alpha = "none")

armed_map
```

This shows every crime in out data set coloured by armed or not. It is quite difficult to tell as there are so many crimes that overlap but you can see some areas where there are more concentrated crimes with weapons, such as the centre.

```{r}
arrest_map <- ggmap(la_map) +
  geom_point(data = summary_by_area, aes(x = avg_lon, y = avg_lat, color = Percent_Arrests, size = 3))+
  theme(
    plot.title = element_text(size = 10),  # Adjust the size here
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
  ) +
  labs(
    title = "Map of LA showing % of Crimes ending in Arrest by Area"
  ) +
  guides(size = "none") +
  scale_color_gradient(low = "blue", high = "red") 
#arrest_map


armed_map1 <- ggmap(la_map) +
  geom_point(data = summary_by_area, aes(x = avg_lon, y = avg_lat, color = Percent_Armed, size = 3))+
  theme(
    plot.title = element_text(size = 10),  # Adjust the size here
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
  ) +
  labs(
    title = "Map of LA showing % of Armed Crimes by Area"
  ) +
  guides(size = "none") +
  scale_color_gradient(low = "blue", high = "red") 
#armed_map1

library(gridExtra)
grid.arrange(arrest_map, armed_map1, nrow=1)
```

From this map, we can see there are areas particularly towards the north and centre where there are a higher percentage of armed crimes and crimes that lead to arrests. This indicates that both armed and arrested may be good variables to help cluster our areas into high-low crime. 

#### Creating derived variables for part 2
```{r Create Vulnerability Metric}
crime$Vict_Age <- ifelse(crime$Vict_Age <= 0, NA, crime$Vict_Age)
crime$Vulnerability <- 0

 createVuln <- function(row){
   x <-  0
  if(!is.na(row['Vict_Sex'])){ #adding points for F
    if (row['Vict_Sex'] == "F"){
      x  <- x + 3
    }
  }
  
  if(!is.na(row['Vict_Age'])){ #adding points for Age
    if (as.numeric(row['Vict_Age']) < 18){
      x  <- x + 18 - as.numeric(row['Vict_Age'])
    }
    
    else if (as.numeric(row['Vict_Age']) > 60){
      x <- x + as.numeric(row['Vict_Age']) - 60
    }
  }
   return(x)
}
crime$Vulnerability <- apply(crime, 1, createVuln)
```


```{r Create Severity Metric}
#Ranked our crimes in terms of hierarchy and if part 1 or 2 offense
rank_code <- crime %>% select(Crime_Code_Desc, Crime_Code, Part_1_2)%>% distinct(Crime_Code_Desc,Crime_Code, Part_1_2) %>%  arrange(desc(Part_1_2), desc(Crime_Code)) %>%  mutate(Severity = row_number())

#Join on overall CrimeCode --> Do this for Crime Code 1, 2, 3, 4
rank_code <- rank_code %>% select(Severity, Crime_Code)

#Crime Code 1
crime <- left_join(crime, rank_code, by = "Crime_Code")
crime <- crime %>%
  rename(Severity_1 = Severity)

#Crime Code 2
rank_code <- rank_code %>%
  rename(Crm_Cd2 = Crime_Code)
crime <- left_join(crime, rank_code, by = "Crm_Cd2")
crime <- crime %>%
  rename(Severity_2 = Severity)

# Crime Code 3
rank_code <- rank_code %>%
  rename(Crm_Cd3 = Crm_Cd2)
crime <- left_join(crime, rank_code, by = "Crm_Cd3")
crime <- crime %>%
  rename(Severity_3 = Severity)

# Crime Code 4 is all NA, so remove it.
crime <- crime %>%
  select(-c(Crm_Cd4))

# Calculate final severity
#0.75*CRM1 +0.25*CRM2 + 0.1*CRM3 = FINAL SEVERITY
crime$Severity_2[is.na(crime$Severity_2)] <- 0
crime$Severity_3[is.na(crime$Severity_3)] <- 0
crime <- crime %>%
  mutate(Final_Severity = (0.75*Severity_1) + 
  (0.25*Severity_2) + 
  (0.1*Severity_3))
```

```{r Weapons and arrests}
# Arrests --> count AA (adult arrest) and JA (juvenile arrest)
crime$Adult_Arrest <- ifelse(crime$Status == "AA", 1, 0)
crime$Juv_Arrest <- ifelse(crime$Status == "JA", 1, 0)

# Weapons --> gun (starts with 1), blade (starts with 2)
crime$Weapon_Used_Code <- as.character(crime$Weapon_Used_Code)
crime$Gun <- ifelse(substr(crime$Weapon_Used_Code,1,1) == "1", 1, 0)
crime$Gun <- ifelse(is.na(crime$Gun), 0, crime$Gun)
crime$Blade <- ifelse(substr(crime$Weapon_Used_Code,1,1) == "2", 1, 0)
crime$Blade <- ifelse(is.na(crime$Blade), 0, crime$Blade)
```


```{r Create Final Dataframe}
crime <- crime %>%
  select(-c(DR_NO, Date_Rptd, Part_1_2, Mocode, Location, Cross_Street, Vict_Age, Vict_Sex,
            Crm_Cd1, Crm_Cd2, Crm_Cd3, Vict_Descent, Severity_1, Severity_2, Severity_3))
write.csv(crime, 'crime_data.csv')
```


```{r Group by District}
library(DescTools)
crime$Weapon_Used_Code <- as.numeric(crime$Weapon_Used_Code)

districts <- crime %>% group_by(District_Num) %>%
  summarize(Most_Common_Premis = Mode(Premis_Code, na.rm=TRUE),
            Most_Common_Crime = Mode(Crime_Code, na.rm=TRUE),
            Avg_Vulnerability = mean(Vulnerability),
            Avg_Severity = mean(Final_Severity),
            Avg_LON = mean(LON),
            Avg_LAT = mean(LAT),
            Num_Adult_Arrest = sum(Adult_Arrest),
            Num_Juv_Arrest = sum(Juv_Arrest),
            Num_Gun = sum(Gun),
            Num_Blade = sum(Blade),
            Most_Common_Weapon = Mode(Weapon_Used_Code, na.rm=TRUE))

```


```{r PAM K-Means CLustering}
library(cluster)
library(tibble)

d <-  districts
#select varaibles
clust_data <- ungroup(d) %>% select(-c(Avg_LON, Avg_LAT, District_Num))

#factor non numeric
clust_data$Most_Common_Premis <- as.factor(clust_data$Most_Common_Premis)
clust_data$Most_Common_Crime <- as.factor(clust_data$Most_Common_Crime)
clust_data$Most_Common_Weapon <- as.factor(clust_data$Most_Common_Weapon)


#scale numeric cols
clust_data <- clust_data %>%
    mutate(across(where(is.numeric), scale))


clust_data <- clust_data  %>% 
  mutate(across(where(is.matrix), as.numeric))


gower_dist <- 
  clust_data %>% daisy(metric = "gower")

sil_width <- c(NA)
for (i in 2:20){
  pam_fit <- pam(gower_dist, diss =TRUE, k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width
}


sil_width %>% 
  as_tibble() %>% 
   rowid_to_column() %>% 
   filter(rowid %in% c(2:20)) %>% 
   ggplot(aes(rowid, value)) +
   geom_line(colour  = 'black', size = 0.7) +
   geom_point(colour = 'black', size = 1.3) +
   theme_minimal() +
   labs(title = 'Silhouette Widths of k-medoid Clusters',
        x     = "Number of clusters",
        y     = 'Silhouette Width') +
   theme(plot.title = element_text(hjust = 0.5))

sil_width %>% 
  as_tibble() %>% 
   rowid_to_column()
```
Looking at this graph, both 7 and 13 are local maximums so we will look at the clustering for both of these.

```{r}
library(Rtsne)

pam_fit7 <- pam(gower_dist, diss =TRUE, k = 7)
pam_fit13 <- pam(gower_dist, diss =TRUE, k = 13)



tsne_obj7 <- Rtsne(gower_dist, is_distance = TRUE)
tsne_obj7$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit7$clustering)) %>% 
  # plot
  ggplot(aes(x = X, y = Y, colour = cluster)) +
  geom_point()  +
  theme_light() +
  labs(title     = 't-SNE 2D Projections of 7-medoid Clusters')  +
  theme(plot.title = element_text(hjust = 0.5))



tsne_obj13 <- Rtsne(gower_dist, is_distance = TRUE)
tsne_obj13$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit13$clustering)) %>% 
  # plot
  ggplot(aes(x = X, y = Y, colour = cluster)) +
  geom_point()  +
  theme_light() +
  labs(title     = 't-SNE 2D Projections of 13-medoid Clusters')  +
  theme(plot.title = element_text(hjust = 0.5))
```


```{r}
library(tidyr)
# Extract clusters
clusters_13 <- pam_fit13$cluster
# Extract centers
#centers_13 <- pam_fit13$medoids
temp <- cbind.data.frame(clust_data, clusters_13)
centers <- temp %>% 
  group_by(clusters_13) %>%
  summarise()

res_mat <- as.data.frame(matrix(NA, nrow = length(unique(clusters_13)), ncol = 6))

for(i in 1:nrow(res_mat)){
  res_mat[i,] <- colMeans(clust_data[which(clusters_13 == i), c(3:8) ], na.rm  =TRUE)
}

names(res_mat) <- names(clust_data)[c(3:8)]
# Create cluster vector
cluster <- c(1:13)
# Join cluster vector and centers
center_df <- data.frame(cluster, res_mat)

# Reshape the data
center_reshape <- gather(center_df, features, values, Avg_Vulnerability:Num_Blade)
# View result
head(center_reshape)

# Create plot
g_heat_2 <- ggplot(data = center_reshape, # Set dataset
                   aes(x = features, y = cluster, fill = values)) + # Set aesthetics
  scale_y_continuous(breaks = seq(1, 13, by = 1)) + # Set y axis breaks
  geom_tile() + # Set geom tile for heatmap
  coord_equal() +  # Set coord equal 
  theme_bw() + # Set theme
  scale_fill_gradient2(low = "blue", # Choose low color
                       mid = "white", # Choose mid color
                       high = "red", # Choose high color
                       midpoint =0, # Choose mid point
                       space = "Lab", 
                       na.value ="grey", # Choose NA value
                       guide = "colourbar", # Set color bar
                       aesthetics = "fill") + # Select aesthetics to apply
  coord_flip() # Rotate plot
# Generate plot
g_heat_2
```
Group 10- lots of guns/blade/arrests
Group 11- high vulnerability and severity, low g/b/a
Group 4- high vulnerability
Group 1- safest

```{r}
d_details <- d %>% select(District_Num, Avg_LON, Avg_LAT)
length(clusters_13)
named_clust <- cbind(d_details, clusters_13) %>% rename( "Cluster_Num" = `...4`)

categoric_added <- cbind(named_clust, d[,c(2, 3, 12)])  
categoric_added <- categoric_added[categoric_added$Cluster_Num %in% c(1, 4, 10, 11),]

sum_by_cluster <- categoric_added %>% 
  group_by(Cluster_Num) %>%
  select(-District_Num) %>%
  mutate(modePrem = Mode(Most_Common_Premis),
         modeCrime = Mode(Most_Common_Crime),
         modeWeapon = Mode(Most_Common_Weapon),
         avgLat = mean(Avg_LAT),
         avgLon = mean(Avg_LON))

sum_by_cluster
```


```{r Clusters by Color Map}

cluster_map <- ggmap(la_map) +
  geom_point(data = sum_by_cluster, aes(x = Avg_LON, y = Avg_LAT, color = as.factor(Cluster_Num)), size = 2)+
  theme(
    plot.title = element_text(size = 10),  # Adjust the size here
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
  ) +
  labs(
    title = "Map of LA showing our Highlighted Clusters",
    color = "Cluster Number"
  ) +
  guides(size = "none") 
cluster_map
```


#### Prediction

Our clusters of interest are 1, 4, 10, and 11.

In order to analyze these clusters, we'll assign the cluster number back to the entries in our original crime dataframe and then subset clusters of interest.
```{r Put cluster numbers back}
clust_crime <- crime %>%
  left_join(named_clust, by = "District_Num")
```

- for each cluster, predict the crime code + predict time of day
  - time series models, random forest?
  
- crime code <-- date_occurred, time_occurred, blade, adult_arrest, juv_arrest, gun
- time_occurred <-- crime_code, blade, adult_arrest, juv_arrest, gun


Given a district and “violent crime” predict where the next one occurs we can xgboost thst
```{r Make 'violent crime' variable}
# violent crime = crime code < 200 or uses a blade/gun
clust_crime$violent <- ifelse (((clust_crime$Crime_Code < 200) | (clust_crime$Gun == 1) | (clust_crime$Blade == 1)), 1, 0)
```

```{r Find most violent districts}
worst10 <- clust_crime %>% 
  filter(Cluster_Num == 10) %>%
  group_by(District_Num) %>% 
  mutate(sum_violent = sum(violent)) %>%
  arrange(desc(sum_violent)) %>%
  select(District_Num) %>%
  head(1)
worst10$District_Num[1] # District 1249 is of interest in cluster 10
```

Run XGboost on time of day: clean time + date
```{r Clean Time/Date}
library(lubridate)
clust_crime$hour <- as.numeric(clust_crime$Time_Occurred)  %/% 100

clust_crime$Date <- as.Date(mdy_hms(clust_crime$Date_Occurred))
clust_crime$DayOfWeek <- wday(mdy_hms(clust_crime$Date_Occurred), label = TRUE)

day_map <- c(Sun = 1, Mon = 2, Tues = 3, Wed = 4, Thurs = 5, Fri = 6, Sat = 7)
clust_crime$numDayOfWeek <- day_map[clust_crime$DayOfWeek]
```


```{r XGBoost on districts}
library(xgboost)
library(caret)
set.seed(1234567)

# for district 1249, predict time of next crime
dist1249 <- clust_crime %>% filter(District_Num == "1249")

vars <- dist1249 %>%
  select(violent, Crime_Code, Premis_Code, Adult_Arrest, Juv_Arrest, Gun, Blade)
outcome <- dist1249$hour

train_indices <- sample(1:nrow(dist1249), 0.8 * nrow(dist1249))
train_set <- vars[train_indices, ]
test_set <- vars[-train_indices, ]
train_label <- outcome[train_indices]
test_label <- outcome[-train_indices]

dtrain <- xgb.DMatrix(data = as.matrix(train_set), label = train_label)
dtest <- xgb.DMatrix(data = as.matrix(test_set))

# Train the model
hour_model <- xgb.train(data = dtrain, 
                   nrounds = 100,
                   eta = 0.1,
                   objective = "multi:softmax",
                   num_class = 24,
                   eval_metric = "merror")

predictions <- predict(hour_model, dtest)
predictions <- round(predictions,0)
pred_and_test <- cbind.data.frame(predictions, test_label)
confusionMatrix(factor(predictions), factor(test_label))
```

trying a crime model:
```{r}
# whether a crime will be violent
clust_crime2 <- na.omit(clust_crime)
vars <- clust_crime2 %>%
  select(numDayOfWeek, hour, Premis_Code, Area, Vulnerability) %>%
  mutate(Area = as.numeric(Area))
outcome <- clust_crime2$violent

train_indices <- sample(1:nrow(clust_crime2), 0.8 * nrow(clust_crime2))
train_set <- vars[train_indices, ]
test_set <- vars[-train_indices, ]
train_label <- outcome[train_indices]
test_label <- outcome[-train_indices]

dtrain <- xgb.DMatrix(data = as.matrix(train_set), label = train_label)
dtest <- xgb.DMatrix(data = as.matrix(test_set))

violent_model <- xgb.train(data = dtrain, 
                   nrounds = 100,
                   eta = 0.1,
                   objective = "binary:logistic", 
                   eval_metric = "auc",
                   eval_metric = "error")

predictions <- predict(violent_model, dtest)
pred_class <- ifelse(predictions > 0.5, 1, 0)
confusionMatrix(factor(pred_class), factor(test_label))

```

predicting type of violent crime?? --> subset to only violent crime and run the model

```{r}
# different values of date, time, victim, weapon etc, and the most likely type of crime to occur to that person could be extracted.

```


Martin's notes:
- This will be multiclass and predicting the full range of crime types is probably a bit too many levels. One option would be to group similar crimes together (e.g. violent crime) and then based on the other variables predict the type of violent crime that may take place. 
- This could also then work with the creation of a dataset listing different values of date, time, victim, weapon etc, and the most likely type of crime to occur to that person could be extracted. This should also lead to more consistent patterns since the motivations behind auto theft and assault are likely to be quite different. 
- For running multi-class models, XGBoost and Random forest should work well. Random forest will handle it without many modifications. For XGBoost, the evaluation metric changes from “error” to “merror” and when tuning we would then modify the code similarly (e.g. look at test_merror_mean).
